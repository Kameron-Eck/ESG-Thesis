{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "***Load Packages***",
   "id": "bd4ab55b5721fb1d"
  },
  {
   "cell_type": "code",
   "id": "c95dcffa-f97d-4095-bd8b-a9a0fb171d66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T18:39:12.573657Z",
     "start_time": "2024-08-20T18:39:10.761501Z"
    }
   },
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from IPython.display import display_html\n",
    "\n",
    "from splink.duckdb.linker import DuckDBLinker\n",
    "from splink.duckdb.comparison_library import exact_match, levenshtein_at_thresholds\n",
    "from splink.duckdb.blocking_rule_library import block_on\n",
    "import splink.duckdb.comparison_library as cl\n",
    "import splink.duckdb.comparison_template_library as ctl\n",
    "import splink.duckdb.comparison_level_library as cll\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kameron\\AppData\\Local\\Temp\\ipykernel_4232\\3623306441.py:6: SplinkDeprecated: Importing directly from `splink.duckdb.duckdb_comparison_library` is deprecated and will be removed in Splink v4. Please import from `splink.duckdb.comparison_library` going forward.\n",
      "  from splink.duckdb.duckdb_comparison_library import (exact_match, levenshtein_at_thresholds)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "ab22db32-c893-4b4c-aa93-762f1c079c03",
   "metadata": {},
   "source": [
    "__Load Data and prevent panda from placing \"NaN\" into blank cells__"
   ]
  },
  {
   "cell_type": "code",
   "id": "3f7114bb-0df6-477a-8f46-ff1894adcfe5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T01:46:22.878877Z",
     "start_time": "2024-08-17T01:46:18.506924Z"
    }
   },
   "source": [
    "# Load the CSV files with dtype specified as str to ensure all data is read as strings\n",
    "iss_c = pd.read_csv(r'C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Control Variables\\Board Level\\iss.csv', dtype=str, low_memory=False)\n",
    "comp_c = pd.read_csv(r'C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Control Variables\\Board Level\\comp.csv', dtype=str, low_memory=False)\n",
    "\n",
    "# Add a unique_id column starting at 1\n",
    "iss_c['unique_id'] = range(1, len(iss_c) + 1)\n",
    "comp_c['unique_id'] = range(1, len(comp_c) + 1)\n",
    "\n",
    "iss_m = iss_c\n",
    "comp_m = comp_c\n",
    "\n",
    "# Replace NaN values with an empty string in both DataFrames\n",
    "iss_c.fillna(\"\", inplace=True)\n",
    "comp_c.fillna(\"\", inplace=True)\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "780b76e2-ae7f-464d-88a1-ecacee2f7791",
   "metadata": {},
   "source": [
    "__This Section Regaurds Institutional Shareholder Solutions (ISS) Data__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac76850d-1b0e-48fe-ae19-57c8a374006d",
   "metadata": {},
   "source": [
    "*Renaming Columns*"
   ]
  },
  {
   "cell_type": "code",
   "id": "5de31ca6-3cf8-434a-b7ec-94ccd2b7b975",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T01:46:31.173912Z",
     "start_time": "2024-08-17T01:46:31.155185Z"
    }
   },
   "source": [
    "iss_c.rename(columns={'first_name': 'first', 'last_name': 'last', 'fullname': 'full'}, inplace=True)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "623c9d42-4ddc-4e62-90f6-6b4bb53fbcc5",
   "metadata": {},
   "source": [
    "__Establishing Functions__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734b494c-0e0f-4626-ae4d-fda2a0d696e9",
   "metadata": {},
   "source": [
    "*The first function is called \"standardize_names\". This functions cleans the first name column by ensuring the first name comes first and any middle initals or names come second. This adjustment standardizes all the data so that another function (which will be mentioned next) can delineate the first names from the middles names, thus providing data handlers with two seperate columns called \"first\" and \"middle\"*"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T01:46:50.047971Z",
     "start_time": "2024-08-17T01:46:32.722636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# List of common titles with regular expression format for easier matching\n",
    "titles = [r\"JR\\.\", r\"SR\\.\", r\"II\", r\"III\", r\"IV\", r\"M\\.D\\.\", r\"PH\\.D\\.\"]\n",
    "\n",
    "# Function to process name strings and separate titles from the main name\n",
    "def process_names(name):\n",
    "    \"\"\"\n",
    "    This function takes a single name string as input, searches for a predefined list of titles at the end of the name,\n",
    "    removes the title from the name, and returns both the cleaned name and the title separately.\n",
    "    \"\"\"\n",
    "    # Compile a regular expression pattern to find titles, which are optionally preceded by a comma or space\n",
    "    pattern = re.compile(r',?\\s*(' + '|'.join(titles) + r')$')\n",
    "    match = pattern.search(name)\n",
    "    if match:\n",
    "        # If a title is found, remove it from the name\n",
    "        name = pattern.sub('', name)\n",
    "        # Return the cleaned name and the found title, stripped of dots for standardization\n",
    "        return name.strip(), match.group(1).replace('.', '')\n",
    "    # If no title is found, return the original name and None for the title\n",
    "    return name, \"\"\n",
    "\n",
    "# Function to standardize name strings\n",
    "def standardize_names(names):\n",
    "    \"\"\"\n",
    "    This function takes a list of name strings, removes any content in parentheses or double quotes,\n",
    "    normalizes whitespace, converts all to lowercase, and returns the standardized names.\n",
    "    \"\"\"\n",
    "    standardized = []\n",
    "    for name in names:\n",
    "        # Remove content in parentheses and double quotes\n",
    "        name = re.sub(r'\\(.*?\\)', '', name)\n",
    "        name = re.sub(r'\\\".*?\\\"', '', name)\n",
    "        # Replace multiple spaces with a single space, trim, and convert to lower case\n",
    "        name = re.sub(r'\\s+', ' ', name).strip().lower()\n",
    "        standardized.append(name)\n",
    "    return standardized\n",
    "\n",
    "# DataFrame operations assuming 'iss_c' is a predefined DataFrame with 'full' column\n",
    "# Applying 'process_names' to 'full' column and splitting results into new 'full' and 'title' columns\n",
    "iss_c['full'], iss_c['title'] = zip(*iss_c['full'].apply(process_names))\n",
    "# Applying 'standardize_names' to cleaned 'full' column\n",
    "iss_c['full'] = standardize_names(iss_c['full'])\n",
    "\n",
    "# Function to split a name into first, middle, and last components\n",
    "def split_name(name):\n",
    "    \"\"\"\n",
    "    This function splits a single cleaned name into first, middle, and last name components based on whitespace and initials.\n",
    "    \"\"\"\n",
    "    # Split the name by spaces after trimming excess whitespace\n",
    "    parts = re.split(r'\\s+', name.strip())\n",
    "    # Initialize variables for first, middle, and last names\n",
    "    first = ''\n",
    "    middle = ''\n",
    "    last = ''\n",
    "    \n",
    "    # Determine how to assign name parts based on the number of components\n",
    "    if len(parts) == 1:\n",
    "        # Only one part, assume it's the first name\n",
    "        first = parts[0]\n",
    "    elif len(parts) == 2:\n",
    "        # Two parts, assign first and last names\n",
    "        first, last = parts\n",
    "    else:\n",
    "        # More than two parts, check for initials and assign accordingly\n",
    "        initial_indices = [i for i, part in enumerate(parts) if re.match(r'^[a-zA-Z]\\.$', part)]\n",
    "        if initial_indices:\n",
    "            if initial_indices[0] == 0 and len(initial_indices) == 1:\n",
    "                middle = parts[0]  # One initial, assume it's a middle name\n",
    "                first = parts[1]\n",
    "                last = ' '.join(parts[2:])\n",
    "            else:\n",
    "                first = parts[0]\n",
    "                middle = ' '.join(parts[1:-1])\n",
    "                last = parts[-1]\n",
    "        else:\n",
    "            first = parts[0]\n",
    "            middle = ' '.join(parts[1:-1])\n",
    "            last = parts[-1]\n",
    "    \n",
    "    return first, middle, last\n",
    "\n",
    "# Applying 'split_name' to the standardized 'full' column in 'iss_c', splitting results into 'first', 'middle', 'last' columns\n",
    "iss_c[['first', 'middle', 'last']] = iss_c['full'].apply(lambda x: pd.Series(split_name(x)))\n"
   ],
   "id": "3355bd4a9a22bd9e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T01:46:50.141557Z",
     "start_time": "2024-08-17T01:46:50.047971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Specifying the order of the columns\n",
    "column_order = ['title', 'first', 'middle', 'last', 'full']  # desired first columns\n",
    "\n",
    "# Add the rest of the columns dynamically\n",
    "column_order.extend([col for col in iss_c.columns if col not in column_order])\n",
    "\n",
    "# Reindex the DataFrame according to the new column order\n",
    "iss_c = iss_c[column_order]"
   ],
   "id": "79bb096c221b5bb6",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "e04b9dcc-b780-4b3f-9b7d-97db83e580d5",
   "metadata": {},
   "source": "*Clean Names*"
  },
  {
   "cell_type": "code",
   "id": "b0343ecc-5ab3-4ce8-9ab9-e3344f7d34fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T01:46:50.675740Z",
     "start_time": "2024-08-17T01:46:50.141557Z"
    }
   },
   "source": [
    "# List of columns to clean\n",
    "columns_to_clean = ['title', 'first', 'middle', 'last', 'full']\n",
    "\n",
    "# Removing non-alphabetical characters and spaces\n",
    "for column in columns_to_clean:\n",
    "    iss_c[column] = iss_c[column].str.replace('[^a-zA-Z]', '', regex=True)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "903619b8-3fcf-46f3-9798-75a853dd5def",
   "metadata": {},
   "source": [
    "*convert the 9 digit cusip ids to 8 digit cusips*"
   ]
  },
  {
   "cell_type": "code",
   "id": "cb701a79-5fc0-471c-afa2-0b7fdf7bbfdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T01:46:50.714930Z",
     "start_time": "2024-08-17T01:46:50.675740Z"
    }
   },
   "source": [
    "iss_c['cusip'] = iss_c['cusip'].str[:-1]"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "550680e1-bc09-4523-bf3d-cb26470a56c0",
   "metadata": {},
   "source": [
    "*Concatenate the year and cusip column. This will be important for using a blocking function with SPlink later.*"
   ]
  },
  {
   "cell_type": "code",
   "id": "644f9c24-9b7b-4a95-b22d-c745017b8c57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T01:46:50.767890Z",
     "start_time": "2024-08-17T01:46:50.714930Z"
    }
   },
   "source": [
    "iss_c['cy'] = iss_c['cusip'].str.zfill(8) + iss_c['year'].astype(str)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "a5723349-c90f-4a52-84f4-45e276e78a42",
   "metadata": {},
   "source": [
    "# Prepping Capital IQ Compustat Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a278c1-4da1-4a94-8661-43485b5835d2",
   "metadata": {},
   "source": [
    "__Clean data for standardization__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935a497f-ec23-43b4-8183-d7ce8c52a8da",
   "metadata": {},
   "source": [
    "*Make column headers and data lowercase*"
   ]
  },
  {
   "cell_type": "code",
   "id": "fb0ad278-b5eb-494f-83ed-d91cf56ecd0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T01:46:52.087284Z",
     "start_time": "2024-08-17T01:46:50.767890Z"
    }
   },
   "source": [
    "comp_c.columns = comp_c.columns.str.lower()\n",
    "comp_c = comp_c.apply(lambda col: col.apply(lambda x: x.lower() if isinstance(x, str) else x))"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "1bfe77e3-c3ba-44e2-86e9-665e8d906eb1",
   "metadata": {},
   "source": [
    "*Rename Director Column*"
   ]
  },
  {
   "cell_type": "code",
   "id": "9e2ebd37-a792-4b63-bb1e-f24e8fc6f173",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T01:46:52.176117Z",
     "start_time": "2024-08-17T01:46:52.087284Z"
    }
   },
   "source": [
    "comp_c = comp_c.rename(columns={'dirname': 'full'})\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "1dde2e66-bc77-4865-98e9-b9612eb7a2bb",
   "metadata": {},
   "source": [
    "*Add a unique_id column (important for SPlink later)*"
   ]
  },
  {
   "cell_type": "code",
   "id": "0faeca52-cc35-4eff-b78f-8a250e9bb990",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T01:46:52.229655Z",
     "start_time": "2024-08-17T01:46:52.176117Z"
    }
   },
   "source": [
    "comp_c.loc[:, 'unique_id'] = range(1, len(comp_c) + 1)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "628791a9-3494-4a4b-9624-47463142395d",
   "metadata": {},
   "source": [
    "*Concatenate cusip and year*"
   ]
  },
  {
   "cell_type": "code",
   "id": "285a2d25-2499-41b8-a7b9-ff830a45f27a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T01:46:52.255880Z",
     "start_time": "2024-08-17T01:46:52.229655Z"
    }
   },
   "source": [
    "comp_c['cy'] = comp_c['cusip'] + comp_c['year']"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "cfbbc76c-912b-473e-b3e3-aab3f471fbab",
   "metadata": {},
   "source": [
    "**Split the 'full' column into three new columns and clean them. Then clean the full column.**"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T01:46:52.260172Z",
     "start_time": "2024-08-17T01:46:52.255880Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e9b4ab3fd5c8e978",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T01:47:18.069539Z",
     "start_time": "2024-08-17T01:46:52.260172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Titles to look for\n",
    "titles = [r\"jr\\.\", r\"sr\\.\", r\"ii\", r\"iii\", r\"iv\", r\"md\\.\", r\"phd\\.\"]\n",
    "\n",
    "# Regex to capture titles from the list, preceded by a comma\n",
    "title_regex = r',\\s*(' + '|'.join(titles) + r')'\n",
    "\n",
    "# Function to extract titles and clean the 'full' name\n",
    "def extract_and_clean(row):\n",
    "    import re\n",
    "    # Find all titles in the 'full' column\n",
    "    found_titles = re.findall(title_regex, row['full'])\n",
    "    \n",
    "    # Prioritize family titles over academic ones\n",
    "    family_titles = [t for t in found_titles if t in ['JR.', 'SR.', 'II', 'III', 'IV']]\n",
    "    if family_titles:\n",
    "        # Select the first family title found (since they are prioritized)\n",
    "        selected_title = family_titles[0]\n",
    "    elif found_titles:\n",
    "        # If no family titles, select the first academic title found\n",
    "        selected_title = found_titles[0]\n",
    "    else:\n",
    "        # If no titles are found, return None\n",
    "        selected_title = \"\"\n",
    "    \n",
    "    # Remove anything after the first comma (including the comma itself)\n",
    "    cleaned_name = re.split(r',', row['full'])[0]\n",
    "    \n",
    "    return pd.Series([cleaned_name, selected_title])\n",
    "\n",
    "# Apply the function and update the DataFrame\n",
    "comp_c[['full', 'title']] = comp_c.apply(extract_and_clean, axis=1)\n"
   ],
   "id": "6ba955b4b155503b",
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "dfbcbf21-f9f7-4ef7-ae13-c20b2ddea908",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T01:47:36.708213Z",
     "start_time": "2024-08-17T01:47:18.069539Z"
    }
   },
   "source": [
    "# Function to split names into first, middle, and last\n",
    "def split_name(name):\n",
    "    # Remove extra spaces and split the name\n",
    "    parts = re.split(r'\\s+', name.strip())\n",
    "    first = ''\n",
    "    middle = ''\n",
    "    last = ''\n",
    "    \n",
    "    # Analyze the parts to assign to first, middle, last\n",
    "    if len(parts) == 1:\n",
    "        first = parts[0]  # Only one part, assume first name\n",
    "    elif len(parts) == 2:\n",
    "        first, last = parts\n",
    "    else:\n",
    "        # Check for initials in parts\n",
    "        initial_indices = [i for i, part in enumerate(parts) if re.match(r'^[a-zA-Z]\\.$', part)]\n",
    "        if initial_indices:\n",
    "            # If the first part is an initial and directly precedes the first name\n",
    "            if initial_indices[0] == 0 and len(initial_indices) == 1:\n",
    "                middle = parts[0]  # Just one initial as middle name\n",
    "                first = parts[1]\n",
    "                last = ' '.join(parts[2:])\n",
    "            else:\n",
    "                first = parts[0]\n",
    "                middle = ' '.join(parts[1:-1])\n",
    "                last = parts[-1]\n",
    "        else:\n",
    "            first = parts[0]\n",
    "            middle = ' '.join(parts[1:-1])\n",
    "            last = parts[-1]\n",
    "    \n",
    "    return first, middle, last\n",
    "\n",
    "\n",
    "# Apply the function to each name in the 'dirname' column\n",
    "comp_c[['first', 'middle', 'last']] = comp_c['full'].apply(lambda x: pd.Series(split_name(x)))"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T01:47:37.616284Z",
     "start_time": "2024-08-17T01:47:36.708213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Specifying the order of the columns\n",
    "column_order = ['title','first', 'middle', 'last', 'full']  # desired first columns\n",
    "\n",
    "# Add the rest of the columns dynamically\n",
    "column_order.extend([col for col in comp_c.columns if col not in column_order])\n",
    "\n",
    "# Reindex the DataFrame according to the new column order\n",
    "comp_c = comp_c[column_order]\n",
    "\n",
    "# List of columns to clean\n",
    "columns_to_clean = ['first', 'middle', 'last', 'full', 'title']\n",
    "\n",
    "# Removing non-alphabetical characters (and spaces)\n",
    "for column in columns_to_clean:\n",
    "    comp_c[column] = comp_c[column].str.replace('[^a-zA-Z]', '', regex=True)"
   ],
   "id": "fe21d1ea1b5a3f4e",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T01:47:38.218735Z",
     "start_time": "2024-08-17T01:47:37.616284Z"
    }
   },
   "cell_type": "code",
   "source": "comp_c ",
   "id": "d7a967461c16784",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       title     first middle       last              full   gvkey dirnbr  \\\n",
       "0                 marc    jay    walfish    marcjaywalfish  001004      1   \n",
       "1               ronald      b    woodard    ronaldbwoodard  001004      2   \n",
       "2              patrick      j      kelly     patrickjkelly  001004      3   \n",
       "3                james      e    goodwin     jamesegoodwin  001004      4   \n",
       "4               ronald      r   fogleman   ronaldrfogleman  001004      5   \n",
       "...      ...       ...    ...        ...               ...     ...    ...   \n",
       "246807          joseph          alvarado    josephalvarado  328795      5   \n",
       "246808        kimberly      s      lubel    kimberlyslubel  328795      6   \n",
       "246809           julie      a    piggott     julieapiggott  328795      7   \n",
       "246810         jeffrey      a      craig     jeffreyacraig  328795      8   \n",
       "246811          steven      j  demetriou  stevenjdemetriou  328795      9   \n",
       "\n",
       "       cash_fees stock_awards option_awards  ...  \\\n",
       "0             80        71.64             0  ...   \n",
       "1           82.5        71.64             0  ...   \n",
       "2           72.5        71.64             0  ...   \n",
       "3             85        71.64             0  ...   \n",
       "4          78.75        71.64             0  ...   \n",
       "...          ...          ...           ...  ...   \n",
       "246807       130      130.046             0  ...   \n",
       "246808       110      130.046             0  ...   \n",
       "246809       110      130.046             0  ...   \n",
       "246810       130      130.046             0  ...   \n",
       "246811   100.833      162.559             0  ...   \n",
       "\n",
       "                                                naicsdesc  \\\n",
       "0       transportation equipment and supplies (except ...   \n",
       "1       transportation equipment and supplies (except ...   \n",
       "2       transportation equipment and supplies (except ...   \n",
       "3       transportation equipment and supplies (except ...   \n",
       "4       transportation equipment and supplies (except ...   \n",
       "...                                                   ...   \n",
       "246807          fabricated structural metal manufacturing   \n",
       "246808          fabricated structural metal manufacturing   \n",
       "246809          fabricated structural metal manufacturing   \n",
       "246810          fabricated structural metal manufacturing   \n",
       "246811          fabricated structural metal manufacturing   \n",
       "\n",
       "                           inddesc spcode ticker sub_tele   naics spindex  \\\n",
       "0              aerospace & defense     sm    air      630  423860    2010   \n",
       "1              aerospace & defense     sm    air      630  423860    2010   \n",
       "2              aerospace & defense     sm    air      630  423860    2010   \n",
       "3              aerospace & defense     sm    air      630  423860    2010   \n",
       "4              aerospace & defense     sm    air      630  423860    2010   \n",
       "...                            ...    ...    ...      ...     ...     ...   \n",
       "246807  construction & engineering     sm    aca      972  332312    2010   \n",
       "246808  construction & engineering     sm    aca      972  332312    2010   \n",
       "246809  construction & engineering     sm    aca      972  332312    2010   \n",
       "246810  construction & engineering     sm    aca      972  332312    2010   \n",
       "246811  construction & engineering     sm    aca      972  332312    2010   \n",
       "\n",
       "         sic unique_id            cy  \n",
       "0       5080         1  000361102010  \n",
       "1       5080         2  000361102010  \n",
       "2       5080         3  000361102010  \n",
       "3       5080         4  000361102010  \n",
       "4       5080         5  000361102010  \n",
       "...      ...       ...           ...  \n",
       "246807  3440    246808  039653102023  \n",
       "246808  3440    246809  039653102023  \n",
       "246809  3440    246810  039653102023  \n",
       "246810  3440    246811  039653102023  \n",
       "246811  3440    246812  039653102023  \n",
       "\n",
       "[246812 rows x 34 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>first</th>\n",
       "      <th>middle</th>\n",
       "      <th>last</th>\n",
       "      <th>full</th>\n",
       "      <th>gvkey</th>\n",
       "      <th>dirnbr</th>\n",
       "      <th>cash_fees</th>\n",
       "      <th>stock_awards</th>\n",
       "      <th>option_awards</th>\n",
       "      <th>...</th>\n",
       "      <th>naicsdesc</th>\n",
       "      <th>inddesc</th>\n",
       "      <th>spcode</th>\n",
       "      <th>ticker</th>\n",
       "      <th>sub_tele</th>\n",
       "      <th>naics</th>\n",
       "      <th>spindex</th>\n",
       "      <th>sic</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>cy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>marc</td>\n",
       "      <td>jay</td>\n",
       "      <td>walfish</td>\n",
       "      <td>marcjaywalfish</td>\n",
       "      <td>001004</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>71.64</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>transportation equipment and supplies (except ...</td>\n",
       "      <td>aerospace &amp; defense</td>\n",
       "      <td>sm</td>\n",
       "      <td>air</td>\n",
       "      <td>630</td>\n",
       "      <td>423860</td>\n",
       "      <td>2010</td>\n",
       "      <td>5080</td>\n",
       "      <td>1</td>\n",
       "      <td>000361102010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>ronald</td>\n",
       "      <td>b</td>\n",
       "      <td>woodard</td>\n",
       "      <td>ronaldbwoodard</td>\n",
       "      <td>001004</td>\n",
       "      <td>2</td>\n",
       "      <td>82.5</td>\n",
       "      <td>71.64</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>transportation equipment and supplies (except ...</td>\n",
       "      <td>aerospace &amp; defense</td>\n",
       "      <td>sm</td>\n",
       "      <td>air</td>\n",
       "      <td>630</td>\n",
       "      <td>423860</td>\n",
       "      <td>2010</td>\n",
       "      <td>5080</td>\n",
       "      <td>2</td>\n",
       "      <td>000361102010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>patrick</td>\n",
       "      <td>j</td>\n",
       "      <td>kelly</td>\n",
       "      <td>patrickjkelly</td>\n",
       "      <td>001004</td>\n",
       "      <td>3</td>\n",
       "      <td>72.5</td>\n",
       "      <td>71.64</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>transportation equipment and supplies (except ...</td>\n",
       "      <td>aerospace &amp; defense</td>\n",
       "      <td>sm</td>\n",
       "      <td>air</td>\n",
       "      <td>630</td>\n",
       "      <td>423860</td>\n",
       "      <td>2010</td>\n",
       "      <td>5080</td>\n",
       "      <td>3</td>\n",
       "      <td>000361102010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>james</td>\n",
       "      <td>e</td>\n",
       "      <td>goodwin</td>\n",
       "      <td>jamesegoodwin</td>\n",
       "      <td>001004</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>71.64</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>transportation equipment and supplies (except ...</td>\n",
       "      <td>aerospace &amp; defense</td>\n",
       "      <td>sm</td>\n",
       "      <td>air</td>\n",
       "      <td>630</td>\n",
       "      <td>423860</td>\n",
       "      <td>2010</td>\n",
       "      <td>5080</td>\n",
       "      <td>4</td>\n",
       "      <td>000361102010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>ronald</td>\n",
       "      <td>r</td>\n",
       "      <td>fogleman</td>\n",
       "      <td>ronaldrfogleman</td>\n",
       "      <td>001004</td>\n",
       "      <td>5</td>\n",
       "      <td>78.75</td>\n",
       "      <td>71.64</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>transportation equipment and supplies (except ...</td>\n",
       "      <td>aerospace &amp; defense</td>\n",
       "      <td>sm</td>\n",
       "      <td>air</td>\n",
       "      <td>630</td>\n",
       "      <td>423860</td>\n",
       "      <td>2010</td>\n",
       "      <td>5080</td>\n",
       "      <td>5</td>\n",
       "      <td>000361102010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246807</th>\n",
       "      <td></td>\n",
       "      <td>joseph</td>\n",
       "      <td></td>\n",
       "      <td>alvarado</td>\n",
       "      <td>josephalvarado</td>\n",
       "      <td>328795</td>\n",
       "      <td>5</td>\n",
       "      <td>130</td>\n",
       "      <td>130.046</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>fabricated structural metal manufacturing</td>\n",
       "      <td>construction &amp; engineering</td>\n",
       "      <td>sm</td>\n",
       "      <td>aca</td>\n",
       "      <td>972</td>\n",
       "      <td>332312</td>\n",
       "      <td>2010</td>\n",
       "      <td>3440</td>\n",
       "      <td>246808</td>\n",
       "      <td>039653102023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246808</th>\n",
       "      <td></td>\n",
       "      <td>kimberly</td>\n",
       "      <td>s</td>\n",
       "      <td>lubel</td>\n",
       "      <td>kimberlyslubel</td>\n",
       "      <td>328795</td>\n",
       "      <td>6</td>\n",
       "      <td>110</td>\n",
       "      <td>130.046</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>fabricated structural metal manufacturing</td>\n",
       "      <td>construction &amp; engineering</td>\n",
       "      <td>sm</td>\n",
       "      <td>aca</td>\n",
       "      <td>972</td>\n",
       "      <td>332312</td>\n",
       "      <td>2010</td>\n",
       "      <td>3440</td>\n",
       "      <td>246809</td>\n",
       "      <td>039653102023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246809</th>\n",
       "      <td></td>\n",
       "      <td>julie</td>\n",
       "      <td>a</td>\n",
       "      <td>piggott</td>\n",
       "      <td>julieapiggott</td>\n",
       "      <td>328795</td>\n",
       "      <td>7</td>\n",
       "      <td>110</td>\n",
       "      <td>130.046</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>fabricated structural metal manufacturing</td>\n",
       "      <td>construction &amp; engineering</td>\n",
       "      <td>sm</td>\n",
       "      <td>aca</td>\n",
       "      <td>972</td>\n",
       "      <td>332312</td>\n",
       "      <td>2010</td>\n",
       "      <td>3440</td>\n",
       "      <td>246810</td>\n",
       "      <td>039653102023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246810</th>\n",
       "      <td></td>\n",
       "      <td>jeffrey</td>\n",
       "      <td>a</td>\n",
       "      <td>craig</td>\n",
       "      <td>jeffreyacraig</td>\n",
       "      <td>328795</td>\n",
       "      <td>8</td>\n",
       "      <td>130</td>\n",
       "      <td>130.046</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>fabricated structural metal manufacturing</td>\n",
       "      <td>construction &amp; engineering</td>\n",
       "      <td>sm</td>\n",
       "      <td>aca</td>\n",
       "      <td>972</td>\n",
       "      <td>332312</td>\n",
       "      <td>2010</td>\n",
       "      <td>3440</td>\n",
       "      <td>246811</td>\n",
       "      <td>039653102023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246811</th>\n",
       "      <td></td>\n",
       "      <td>steven</td>\n",
       "      <td>j</td>\n",
       "      <td>demetriou</td>\n",
       "      <td>stevenjdemetriou</td>\n",
       "      <td>328795</td>\n",
       "      <td>9</td>\n",
       "      <td>100.833</td>\n",
       "      <td>162.559</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>fabricated structural metal manufacturing</td>\n",
       "      <td>construction &amp; engineering</td>\n",
       "      <td>sm</td>\n",
       "      <td>aca</td>\n",
       "      <td>972</td>\n",
       "      <td>332312</td>\n",
       "      <td>2010</td>\n",
       "      <td>3440</td>\n",
       "      <td>246812</td>\n",
       "      <td>039653102023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246812 rows × 34 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T01:47:38.300183Z",
     "start_time": "2024-08-17T01:47:38.218735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate the count of unique CUSIPs per year for both dataframes\n",
    "unique_cusip_per_year_iss = iss_c.groupby('year')['cusip'].nunique()\n",
    "unique_cusip_per_year_comp = comp_c.groupby('year')['cusip'].nunique()\n",
    "\n",
    "# Create a DataFrame to compare the counts from both datasets\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Unique CUSIPs in ISS': unique_cusip_per_year_iss,\n",
    "    'Unique CUSIPs in COMP': unique_cusip_per_year_comp\n",
    "})\n",
    "\n",
    "# Calculate the absolute difference in unique CUSIPs per year between the two datasets\n",
    "comparison_df['Difference'] = comparison_df['Unique CUSIPs in ISS'].sub(comparison_df['Unique CUSIPs in COMP']).abs()\n",
    "\n",
    "# Optionally, calculate the percentage match\n",
    "comparison_df['Match Percentage'] = 100 * (1 - (comparison_df['Difference'] / comparison_df[['Unique CUSIPs in ISS', 'Unique CUSIPs in COMP']].max(axis=1)))\n",
    "\n",
    "# Display the comparison DataFrame\n",
    "print(comparison_df)"
   ],
   "id": "d3783e3259eab412",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unique CUSIPs in ISS  Unique CUSIPs in COMP  Difference  \\\n",
      "year                                                            \n",
      "2010                  1481                   2229         748   \n",
      "2011                  1470                   2192         722   \n",
      "2012                  1497                   2173         676   \n",
      "2013                  1515                   2169         654   \n",
      "2014                  1499                   2163         664   \n",
      "2015                  1505                   2106         601   \n",
      "2016                  1508                   2042         534   \n",
      "2017                  1515                   1979         464   \n",
      "2018                  1506                   1947         441   \n",
      "2019                  1526                   1888         362   \n",
      "2020                  1519                   1859         340   \n",
      "2021                  1491                   1819         328   \n",
      "2022                  1515                   1782         267   \n",
      "2023                  1544                   1650         106   \n",
      "\n",
      "      Match Percentage  \n",
      "year                    \n",
      "2010         66.442351  \n",
      "2011         67.062044  \n",
      "2012         68.890934  \n",
      "2013         69.847856  \n",
      "2014         69.301896  \n",
      "2015         71.462488  \n",
      "2016         73.849167  \n",
      "2017         76.553815  \n",
      "2018         77.349769  \n",
      "2019         80.826271  \n",
      "2020         81.710597  \n",
      "2021         81.968114  \n",
      "2022         85.016835  \n",
      "2023         93.575758  \n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "ea8b38f9-47df-433c-b139-608d0fcc6a71",
   "metadata": {},
   "source": [
    "Compare the data sets"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T01:47:38.335017Z",
     "start_time": "2024-08-17T01:47:38.300183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Filter both DataFrames for rows where 'cy' equals '000360202010'\n",
    "comp_c_filtered = comp_c[comp_c['cy'] == '000360202011']\n",
    "iss_c_filtered = iss_c[iss_c['cy'] == '000360202011']\n",
    "\n",
    "# Since we're now directly targeting specific entries, sorting may not be necessary, but we'll maintain structure\n",
    "comp_c_sorted = comp_c_filtered[['unique_id', 'cusip', 'year', 'first', 'middle', 'last', 'full', 'cy']].head(5)\n",
    "iss_c_sorted = iss_c_filtered[['unique_id', 'cusip', 'year', 'first', 'middle', 'last', 'full', 'cy']].head(5)\n",
    "\n",
    "# Convert dataframes to HTML\n",
    "comp_c_html = comp_c_sorted.to_html()\n",
    "iss_c_html = iss_c_sorted.to_html()\n",
    "space = '&nbsp;'*10  # Adjust space as needed\n",
    "\n",
    "# Combine the HTML strings with space in between\n",
    "html_string = f'<div style=\"float: left;\">{comp_c_html}</div>{space}<div style=\"float: left;\">{iss_c_html}</div>'\n",
    "\n",
    "# Display the HTML string in the notebook\n",
    "display_html(html_string, raw=True)\n"
   ],
   "id": "b2cee06278a621d7",
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"float: left;\"><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>cusip</th>\n",
       "      <th>year</th>\n",
       "      <th>first</th>\n",
       "      <th>middle</th>\n",
       "      <th>last</th>\n",
       "      <th>full</th>\n",
       "      <th>cy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119763</th>\n",
       "      <td>119764</td>\n",
       "      <td>00036020</td>\n",
       "      <td>2011</td>\n",
       "      <td>john</td>\n",
       "      <td>b</td>\n",
       "      <td>johnson</td>\n",
       "      <td>johnbjohnson</td>\n",
       "      <td>000360202011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119764</th>\n",
       "      <td>119765</td>\n",
       "      <td>00036020</td>\n",
       "      <td>2011</td>\n",
       "      <td>arthur</td>\n",
       "      <td>h</td>\n",
       "      <td>mcelroy</td>\n",
       "      <td>arthurhmcelroy</td>\n",
       "      <td>000360202011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119765</th>\n",
       "      <td>119766</td>\n",
       "      <td>00036020</td>\n",
       "      <td>2011</td>\n",
       "      <td>paul</td>\n",
       "      <td>kenneth</td>\n",
       "      <td>lackey</td>\n",
       "      <td>paulkennethlackey</td>\n",
       "      <td>000360202011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119766</th>\n",
       "      <td>119767</td>\n",
       "      <td>00036020</td>\n",
       "      <td>2011</td>\n",
       "      <td>jack</td>\n",
       "      <td>e</td>\n",
       "      <td>short</td>\n",
       "      <td>jackeshort</td>\n",
       "      <td>000360202011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119767</th>\n",
       "      <td>119768</td>\n",
       "      <td>00036020</td>\n",
       "      <td>2011</td>\n",
       "      <td>joseph</td>\n",
       "      <td>e</td>\n",
       "      <td>cappy</td>\n",
       "      <td>josephecappy</td>\n",
       "      <td>000360202011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<div style=\"float: left;\"><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>cusip</th>\n",
       "      <th>year</th>\n",
       "      <th>first</th>\n",
       "      <th>middle</th>\n",
       "      <th>last</th>\n",
       "      <th>full</th>\n",
       "      <th>cy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>630</td>\n",
       "      <td>00036020</td>\n",
       "      <td>2011</td>\n",
       "      <td>joseph</td>\n",
       "      <td>e</td>\n",
       "      <td>cappy</td>\n",
       "      <td>josephecappy</td>\n",
       "      <td>000360202011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>631</td>\n",
       "      <td>00036020</td>\n",
       "      <td>2011</td>\n",
       "      <td>norman</td>\n",
       "      <td>h</td>\n",
       "      <td>asbjornson</td>\n",
       "      <td>normanhasbjornson</td>\n",
       "      <td>000360202011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>632</td>\n",
       "      <td>00036020</td>\n",
       "      <td>2011</td>\n",
       "      <td>john</td>\n",
       "      <td>b</td>\n",
       "      <td>johnson</td>\n",
       "      <td>johnbjohnson</td>\n",
       "      <td>000360202011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>633</td>\n",
       "      <td>00036020</td>\n",
       "      <td>2011</td>\n",
       "      <td>jack</td>\n",
       "      <td>e</td>\n",
       "      <td>short</td>\n",
       "      <td>jackeshort</td>\n",
       "      <td>000360202011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>634</td>\n",
       "      <td>00036020</td>\n",
       "      <td>2011</td>\n",
       "      <td>paul</td>\n",
       "      <td>k</td>\n",
       "      <td>lackey</td>\n",
       "      <td>paulklackey</td>\n",
       "      <td>000360202011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "64afe4dc-a8e3-44f6-bef5-699538e01173",
   "metadata": {},
   "source": [
    "# Merging Compustat and ISS (Former risk metrics)"
   ]
  },
  {
   "cell_type": "code",
   "id": "92bd3e30-dc79-4f23-903d-6ca2a159ab36",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-08-17T01:47:38.398663Z",
     "start_time": "2024-08-17T01:47:38.335017Z"
    }
   },
   "source": [
    "# Selecting specific columns from comp_c to create df_r\n",
    "df_r = comp_c[['unique_id', 'cusip', 'year', 'cy', 'first', 'middle', 'last', 'full']]\n",
    "\n",
    "# Selecting specific columns from iss_c to create df_l\n",
    "df_l = iss_c[['unique_id', 'cusip', 'year', 'cy', 'first', 'middle', 'last', 'full']]\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "a3d9f939-81f9-4aeb-9661-80862868ec60",
   "metadata": {},
   "source": "h*Double Check Data Types Mefore Merge*"
  },
  {
   "cell_type": "code",
   "id": "8d15cce4-7522-45e2-b371-f1e31b58ac50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T01:47:38.403681Z",
     "start_time": "2024-08-17T01:47:38.398663Z"
    }
   },
   "source": [
    "# Get the data types of the columns\n",
    "df_r_dtypes = df_r.dtypes\n",
    "df_l_dtypes = df_l.dtypes\n",
    "\n",
    "# Print the data types\n",
    "print(\"Data types of columns in df_r:\")\n",
    "print(df_r_dtypes)\n",
    "print(\"\\nData types of columns in df_l:\")\n",
    "print(df_l_dtypes)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of columns in df_r:\n",
      "unique_id     int64\n",
      "cusip        object\n",
      "year         object\n",
      "cy           object\n",
      "first        object\n",
      "middle       object\n",
      "last         object\n",
      "full         object\n",
      "dtype: object\n",
      "\n",
      "Data types of columns in df_l:\n",
      "unique_id     int64\n",
      "cusip        object\n",
      "year         object\n",
      "cy           object\n",
      "first        object\n",
      "middle       object\n",
      "last         object\n",
      "full         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "3968250b-c4f9-4b45-a5ff-a46843bc6d36",
   "metadata": {},
   "source": [
    "*SPlink settings*"
   ]
  },
  {
   "cell_type": "code",
   "id": "22c60352-ae2b-4709-a42d-9b4f70983630",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T01:47:38.656373Z",
     "start_time": "2024-08-17T01:47:38.403681Z"
    }
   },
   "source": [
    "\n",
    "settings = {\n",
    "    \"link_type\": \"link_only\",\n",
    "    \"blocking_rules_to_generate_predictions\": [\n",
    "        block_on(\"cy\",salting_partitions=2)\n",
    "    ],\n",
    "    \"comparisons\": [\n",
    "        ctl.name_comparison(\"first\"),\n",
    "        ctl.name_comparison(\"full\"),\n",
    "        ctl.name_comparison(\"last\"),\n",
    "        ctl.name_comparison(\"middle\"),\n",
    "        cl.exact_match(\"year\"),\n",
    "        cl.exact_match(\"cusip\"),\n",
    "    ],       \n",
    "}\n",
    "\n",
    "linker = DuckDBLinker([df_l, df_r], settings,connection=\":temporary:\", input_table_aliases=[\"comp\", \"iss\"])"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "id": "b6d9cddb-fad5-4fff-9128-b84ab5f91092",
   "metadata": {},
   "source": [
    "*Check data quality*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4553425c-534b-4f1e-84ad-9aa8fafb19e1",
   "metadata": {},
   "source": [
    "linker.completeness_chart()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a949fe-1bfb-4e4e-ae45-b78e16d59b75",
   "metadata": {},
   "source": [
    "*Deterministic rules are crucial in the linking process, defining which comparisons are accepted or rejected. I use the Jaro-Winkler similarity method, which prioritizes the match of the initial characters in two strings and de-emphasizes later discrepancies. This approach is valuable when dealing with slight variations in dataset spelling. For example, \"Lee Wan Hu\" and \"Lee W. H.\" would score high, indicating a strong match. However, \"Kyle Moster\" vs. \"Lyle Mester\" would score low due to different initial characters, leading my deterministic rules to exclude such comparisons from progressing to more rigorous matching processes. This ensures efficiency by focusing on the most likely matches.*"
   ]
  },
  {
   "cell_type": "code",
   "id": "c1c2890f-7ed9-4f46-a2c6-ecab1af21f72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T01:47:39.974083Z",
     "start_time": "2024-08-17T01:47:38.657373Z"
    }
   },
   "source": [
    "deterministic_rules = [\n",
    "    \n",
    "    \"jaro_winkler_similarity(r.full, l.full) >= .6 and r.cy = l.cy and jaro_winkler_similarity(r.first, l.first) >= .6 and jaro_winkler_similarity(r.last, l.last) >= .6\",\n",
    "\n",
    "]\n",
    "\n",
    "linker.estimate_probability_two_random_records_match(deterministic_rules, recall=.9)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probability two random records match is estimated to be  2.38e-06.\n",
      "This means that amongst all possible pairwise record comparisons, one in 420,519.23 are expected to match.  With 49,244,670,676 total possible comparisons, we expect a total of around 117,104.44 matching pairs\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "d9b3be12-6f32-4a1e-8123-1ec0dbd857a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T01:47:44.249830Z",
     "start_time": "2024-08-17T01:47:39.974083Z"
    }
   },
   "source": [
    "linker.estimate_u_using_random_sampling(max_pairs=1e6, seed=1)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----- Estimating u probabilities using random sampling -----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf20a9fc0c4e4561806ff600de0712be"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimated u probabilities using random sampling\n",
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - first (no m values are trained).\n",
      "    - full (no m values are trained).\n",
      "    - last (no m values are trained).\n",
      "    - middle (no m values are trained).\n",
      "    - year (no m values are trained).\n",
      "    - cusip (no m values are trained).\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "3433d37e-797e-4588-8b68-29950c0763fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T01:47:56.985800Z",
     "start_time": "2024-08-17T01:47:44.253386Z"
    }
   },
   "source": [
    "session_cusip_year = linker.estimate_parameters_using_expectation_maximisation(block_on(\"cy\"))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Starting EM training session -----\n",
      "\n",
      "Estimating the m probabilities of the model by blocking on:\n",
      "l.\"cy\" = r.\"cy\"\n",
      "\n",
      "Parameter estimates will be made for the following comparison(s):\n",
      "    - first\n",
      "    - full\n",
      "    - last\n",
      "    - middle\n",
      "    - year\n",
      "    - cusip\n",
      "\n",
      "Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cf799c4114b34bf19b86039cb42f940a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:\n",
      "Level All other comparisons on comparison year not observed in dataset, unable to train m value\n",
      "\n",
      "WARNING:\n",
      "Level All other comparisons on comparison cusip not observed in dataset, unable to train m value\n",
      "\n",
      "Iteration 1: Largest change in params was -0.531 in the m_probability of full, level `Exact match full`\n",
      "Iteration 2: Largest change in params was -0.12 in the m_probability of last, level `Exact match last`\n",
      "Iteration 3: Largest change in params was 0.806 in the m_probability of first, level `All other comparisons`\n",
      "Iteration 4: Largest change in params was 0.282 in probability_two_random_records_match\n",
      "Iteration 5: Largest change in params was 1.15e-05 in probability_two_random_records_match\n",
      "\n",
      "EM converged after 5 iterations\n",
      "m probability not trained for year - All other comparisons (comparison vector value: 0). This usually means the comparison level was never observed in the training data.\n",
      "m probability not trained for cusip - All other comparisons (comparison vector value: 0). This usually means the comparison level was never observed in the training data.\n",
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - year (some m values are not trained).\n",
      "    - cusip (some m values are not trained).\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "355f634b-92f8-429f-af9c-6c98c6c28ada",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T01:48:25.563847Z",
     "start_time": "2024-08-17T01:47:56.985800Z"
    }
   },
   "source": "results = linker.predict(threshold_match_probability=0.8)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1eb311d45e0d4abf8dd4c630b999dcca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " -- WARNING --\n",
      "You have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\n",
      "Comparison: 'year':\n",
      "    m values not fully trained\n",
      "Comparison: 'cusip':\n",
      "    m values not fully trained\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T02:37:24.879048Z",
     "start_time": "2024-08-17T02:37:24.565739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results.as_pandas_dataframe()\n",
    "\n",
    "df_r=comp_"
   ],
   "id": "30eb7e9031c7c3d8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        match_weight  match_probability source_dataset_l source_dataset_r  \\\n",
       "0           2.389267           0.839716             comp              iss   \n",
       "1           2.396077           0.840350             comp              iss   \n",
       "2           2.396077           0.840350             comp              iss   \n",
       "3           2.396077           0.840350             comp              iss   \n",
       "4           2.396077           0.840350             comp              iss   \n",
       "...              ...                ...              ...              ...   \n",
       "101557     18.971904           0.999998             comp              iss   \n",
       "101558     18.971904           0.999998             comp              iss   \n",
       "101559     18.971904           0.999998             comp              iss   \n",
       "101560     18.971904           0.999998             comp              iss   \n",
       "101561     18.971904           0.999998             comp              iss   \n",
       "\n",
       "        unique_id_l  unique_id_r   first_l   first_r  gamma_first  \\\n",
       "0             46674       116612       uwe       uwe            4   \n",
       "1            175478        74313      lars      lars            4   \n",
       "2             98288        81663   william   william            4   \n",
       "3             98299        81674   william   william            4   \n",
       "4            142060        91814      ralf      ralf            4   \n",
       "...             ...          ...       ...       ...          ...   \n",
       "101557        28742       245837  theodore  theodore            4   \n",
       "101558         2086       246803   antonio   antonio            4   \n",
       "101559       129514       245306    lesley    lesley            4   \n",
       "101560        28713       245818  theodore  theodore            4   \n",
       "101561        28723       245824  theodore  theodore            4   \n",
       "\n",
       "                    full_l  ...  middle_r  gamma_middle year_l year_r  \\\n",
       "0              uwerohrhoff  ...         f             3   2017   2017   \n",
       "1            larssoerensen  ...    rebien             0   2022   2022   \n",
       "2             williampesce  ...    edward             0   2019   2019   \n",
       "3             williampesce  ...    edward             0   2020   2020   \n",
       "4                ralfrboer  ...  reinhard             0   2012   2012   \n",
       "...                    ...  ...       ...           ...    ...    ...   \n",
       "101557  theodoremarmstrong  ...         m             4   2014   2014   \n",
       "101558     antoniocarrillo  ...                       4   2022   2022   \n",
       "101559         lesleyhhowe  ...         h             4   2013   2013   \n",
       "101560  theodoremarmstrong  ...         m             4   2011   2011   \n",
       "101561  theodoremarmstrong  ...         m             4   2012   2012   \n",
       "\n",
       "        gamma_year   cusip_l   cusip_r  gamma_cusip          cy_l  \\\n",
       "0                1  14880610  14880610            1  148806102017   \n",
       "1                1  88355610  88355610            1  883556102022   \n",
       "2                1  96822320  96822320            1  968223202019   \n",
       "3                1  96822320  96822320            1  968223202020   \n",
       "4                1  72913210  72913210            1  729132102012   \n",
       "...            ...       ...       ...          ...           ...   \n",
       "101557           1  12680430  12680430            1  126804302014   \n",
       "101558           1  03965310  03965310            1  039653102022   \n",
       "101559           1  67070410  67070410            1  670704102013   \n",
       "101560           1  12680430  12680430            1  126804302011   \n",
       "101561           1  12680430  12680430            1  126804302012   \n",
       "\n",
       "                cy_r  \n",
       "0       148806102017  \n",
       "1       883556102022  \n",
       "2       968223202019  \n",
       "3       968223202020  \n",
       "4       729132102012  \n",
       "...              ...  \n",
       "101557  126804302014  \n",
       "101558  039653102022  \n",
       "101559  670704102013  \n",
       "101560  126804302011  \n",
       "101561  126804302012  \n",
       "\n",
       "[101562 rows x 26 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_weight</th>\n",
       "      <th>match_probability</th>\n",
       "      <th>source_dataset_l</th>\n",
       "      <th>source_dataset_r</th>\n",
       "      <th>unique_id_l</th>\n",
       "      <th>unique_id_r</th>\n",
       "      <th>first_l</th>\n",
       "      <th>first_r</th>\n",
       "      <th>gamma_first</th>\n",
       "      <th>full_l</th>\n",
       "      <th>...</th>\n",
       "      <th>middle_r</th>\n",
       "      <th>gamma_middle</th>\n",
       "      <th>year_l</th>\n",
       "      <th>year_r</th>\n",
       "      <th>gamma_year</th>\n",
       "      <th>cusip_l</th>\n",
       "      <th>cusip_r</th>\n",
       "      <th>gamma_cusip</th>\n",
       "      <th>cy_l</th>\n",
       "      <th>cy_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.389267</td>\n",
       "      <td>0.839716</td>\n",
       "      <td>comp</td>\n",
       "      <td>iss</td>\n",
       "      <td>46674</td>\n",
       "      <td>116612</td>\n",
       "      <td>uwe</td>\n",
       "      <td>uwe</td>\n",
       "      <td>4</td>\n",
       "      <td>uwerohrhoff</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>14880610</td>\n",
       "      <td>14880610</td>\n",
       "      <td>1</td>\n",
       "      <td>148806102017</td>\n",
       "      <td>148806102017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.396077</td>\n",
       "      <td>0.840350</td>\n",
       "      <td>comp</td>\n",
       "      <td>iss</td>\n",
       "      <td>175478</td>\n",
       "      <td>74313</td>\n",
       "      <td>lars</td>\n",
       "      <td>lars</td>\n",
       "      <td>4</td>\n",
       "      <td>larssoerensen</td>\n",
       "      <td>...</td>\n",
       "      <td>rebien</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>88355610</td>\n",
       "      <td>88355610</td>\n",
       "      <td>1</td>\n",
       "      <td>883556102022</td>\n",
       "      <td>883556102022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.396077</td>\n",
       "      <td>0.840350</td>\n",
       "      <td>comp</td>\n",
       "      <td>iss</td>\n",
       "      <td>98288</td>\n",
       "      <td>81663</td>\n",
       "      <td>william</td>\n",
       "      <td>william</td>\n",
       "      <td>4</td>\n",
       "      <td>williampesce</td>\n",
       "      <td>...</td>\n",
       "      <td>edward</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>96822320</td>\n",
       "      <td>96822320</td>\n",
       "      <td>1</td>\n",
       "      <td>968223202019</td>\n",
       "      <td>968223202019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.396077</td>\n",
       "      <td>0.840350</td>\n",
       "      <td>comp</td>\n",
       "      <td>iss</td>\n",
       "      <td>98299</td>\n",
       "      <td>81674</td>\n",
       "      <td>william</td>\n",
       "      <td>william</td>\n",
       "      <td>4</td>\n",
       "      <td>williampesce</td>\n",
       "      <td>...</td>\n",
       "      <td>edward</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>96822320</td>\n",
       "      <td>96822320</td>\n",
       "      <td>1</td>\n",
       "      <td>968223202020</td>\n",
       "      <td>968223202020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.396077</td>\n",
       "      <td>0.840350</td>\n",
       "      <td>comp</td>\n",
       "      <td>iss</td>\n",
       "      <td>142060</td>\n",
       "      <td>91814</td>\n",
       "      <td>ralf</td>\n",
       "      <td>ralf</td>\n",
       "      <td>4</td>\n",
       "      <td>ralfrboer</td>\n",
       "      <td>...</td>\n",
       "      <td>reinhard</td>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>72913210</td>\n",
       "      <td>72913210</td>\n",
       "      <td>1</td>\n",
       "      <td>729132102012</td>\n",
       "      <td>729132102012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101557</th>\n",
       "      <td>18.971904</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>comp</td>\n",
       "      <td>iss</td>\n",
       "      <td>28742</td>\n",
       "      <td>245837</td>\n",
       "      <td>theodore</td>\n",
       "      <td>theodore</td>\n",
       "      <td>4</td>\n",
       "      <td>theodoremarmstrong</td>\n",
       "      <td>...</td>\n",
       "      <td>m</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>12680430</td>\n",
       "      <td>12680430</td>\n",
       "      <td>1</td>\n",
       "      <td>126804302014</td>\n",
       "      <td>126804302014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101558</th>\n",
       "      <td>18.971904</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>comp</td>\n",
       "      <td>iss</td>\n",
       "      <td>2086</td>\n",
       "      <td>246803</td>\n",
       "      <td>antonio</td>\n",
       "      <td>antonio</td>\n",
       "      <td>4</td>\n",
       "      <td>antoniocarrillo</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>03965310</td>\n",
       "      <td>03965310</td>\n",
       "      <td>1</td>\n",
       "      <td>039653102022</td>\n",
       "      <td>039653102022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101559</th>\n",
       "      <td>18.971904</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>comp</td>\n",
       "      <td>iss</td>\n",
       "      <td>129514</td>\n",
       "      <td>245306</td>\n",
       "      <td>lesley</td>\n",
       "      <td>lesley</td>\n",
       "      <td>4</td>\n",
       "      <td>lesleyhhowe</td>\n",
       "      <td>...</td>\n",
       "      <td>h</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>67070410</td>\n",
       "      <td>67070410</td>\n",
       "      <td>1</td>\n",
       "      <td>670704102013</td>\n",
       "      <td>670704102013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101560</th>\n",
       "      <td>18.971904</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>comp</td>\n",
       "      <td>iss</td>\n",
       "      <td>28713</td>\n",
       "      <td>245818</td>\n",
       "      <td>theodore</td>\n",
       "      <td>theodore</td>\n",
       "      <td>4</td>\n",
       "      <td>theodoremarmstrong</td>\n",
       "      <td>...</td>\n",
       "      <td>m</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>12680430</td>\n",
       "      <td>12680430</td>\n",
       "      <td>1</td>\n",
       "      <td>126804302011</td>\n",
       "      <td>126804302011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101561</th>\n",
       "      <td>18.971904</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>comp</td>\n",
       "      <td>iss</td>\n",
       "      <td>28723</td>\n",
       "      <td>245824</td>\n",
       "      <td>theodore</td>\n",
       "      <td>theodore</td>\n",
       "      <td>4</td>\n",
       "      <td>theodoremarmstrong</td>\n",
       "      <td>...</td>\n",
       "      <td>m</td>\n",
       "      <td>4</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>12680430</td>\n",
       "      <td>12680430</td>\n",
       "      <td>1</td>\n",
       "      <td>126804302012</td>\n",
       "      <td>126804302012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101562 rows × 26 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T03:05:37.641149Z",
     "start_time": "2024-08-17T03:05:36.468513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results_df = results.as_pandas_dataframe()\n",
    "\n",
    "# Perform the left join\n",
    "m1 = results_df.merge(comp_c, left_on='unique_id_r', right_on='unique_id', how='left')\n",
    "m2 = m1.merge(iss_c, left_on='unique_id_l', right_on='unique_id', how='left')"
   ],
   "id": "46dd128f2fff70a3",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T03:18:05.832547Z",
     "start_time": "2024-08-17T03:18:01.626270Z"
    }
   },
   "cell_type": "code",
   "source": "m2.to_csv(r'C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Control Variables\\Board Level\\iss_comp_merge.csv')",
   "id": "547f883127a85adb",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "abdc5733aca48d6b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
