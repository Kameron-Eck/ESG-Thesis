{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Before running this code, I did the manual work of sorting Open Secrets Campaign Finance data into separate folders. The folders were titled based on the content type (e.g. Individual Contribution, Pac Contributions, etc.).",
   "id": "a745d741f22768d4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "List of all Congressional Canidates",
   "id": "f2d04475d8f5185c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T18:49:12.380640Z",
     "start_time": "2024-08-16T18:49:11.357409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import concurrent.futures\n",
    "\n",
    "# Path to the CSV files\n",
    "cands = r'C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\cands\\*.txt'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "all_files = glob.glob(cands)\n",
    "\n",
    "# List of custom headers\n",
    "headers = [\"Field\", \"Cycle\", \"FECCandID\", \"CID\", \"FirstLastP\", \"Party\", \"DistIDRunFor\", \"DistIDCurr\", \"CurrCand\", \"CycleCand\", \"CRPICO\", \"RecipCode\", \"NoPacs\"]\n",
    "\n",
    "# Function to read a single CSV file with specified headers\n",
    "def read_csv(file):\n",
    "    try:\n",
    "        df = pd.read_csv(file, encoding='ISO-8859-1', delimiter=',', quotechar='|', names=headers, low_memory=False)\n",
    "        print(f\"Successfully read {file}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Use ThreadPoolExecutor to read files in parallel\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    dfs = list(executor.map(read_csv, all_files))\n",
    "\n",
    "# Concatenate all the dataframes in the list into a single dataframe\n",
    "if dfs:\n",
    "    big_df = pd.concat(dfs, ignore_index=True)\n",
    "    print(f\"Shape of the concatenated dataframe: {big_df.shape}\")\n",
    "    \n",
    "    # Save the concatenated dataframe to a single CSV file\n",
    "    output_path = r'C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\cands.csv'\n",
    "    big_df.to_csv(output_path, index=False)\n",
    "    print(f\"Concatenated file saved to {output_path}\")\n",
    "else:\n",
    "    print(\"No dataframes to concatenate.\")\n"
   ],
   "id": "e69b6989715b714a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\cands\\cands14.txt\n",
      "Successfully read C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\cands\\cands20.txt\n",
      "Successfully read C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\cands\\cands12.txt\n",
      "Successfully read C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\cands\\cands10.txt\n",
      "Successfully read C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\cands\\cands22.txt\n",
      "Successfully read C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\cands\\cands18.txt\n",
      "Successfully read C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\cands\\cands16.txt\n",
      "Shape of the concatenated dataframe: (49077, 13)\n",
      "Concatenated file saved to C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\cands.csv\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "List of Committees",
   "id": "11b0e57fc7fd20fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T18:49:14.605379Z",
     "start_time": "2024-08-16T18:49:13.508138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import concurrent.futures\n",
    "\n",
    "# Path to the CSV files\n",
    "cmtes = r'C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\cmtes\\*.txt'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "all_files = glob.glob(cmtes)\n",
    "\n",
    "# List of custom headers\n",
    "headers = [\"Cycle\", \"CmteID\", \"PACShort\", \"Affiliate\", \"Ultorg\", \"RecipID\", \"RecipCode\", \"FECCandID\", \"Party\", \"PrimCode\", \"Source\", \"Sensitive\", \"Foreign\", \"Active\"]\n",
    "\n",
    "# Function to read a single CSV file with specified headers\n",
    "def read_csv(file):\n",
    "    try:\n",
    "        df = pd.read_csv(file, encoding='ISO-8859-1', delimiter=',', quotechar='|', names=headers, low_memory=False)\n",
    "        print(f\"Successfully read {file}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Use ThreadPoolExecutor to read files in parallel\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    dfs = list(executor.map(read_csv, all_files))\n",
    "\n",
    "# Filter out any None values in the list\n",
    "dfs = [df for df in dfs if df is not None]\n",
    "\n",
    "# Concatenate all the dataframes in the list into a single dataframe\n",
    "if dfs:\n",
    "    big_df = pd.concat(dfs, ignore_index=True)\n",
    "    print(f\"Shape of the concatenated dataframe: {big_df.shape}\")\n",
    "    \n",
    "    # Save the concatenated dataframe to a single CSV file\n",
    "    output_path = r'C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\cmtes.csv'\n",
    "    big_df.to_csv(output_path, index=False)\n",
    "    print(f\"Concatenated file saved to {output_path}\")\n",
    "else:\n",
    "    print(\"No dataframes to concatenate.\")\n"
   ],
   "id": "313a6dc8b1374d9a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\cmtes\\cmtes10.txt\n",
      "Successfully read C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\cmtes\\cmtes12.txt\n",
      "Successfully read C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\cmtes\\cmtes16.txt\n",
      "Successfully read C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\cmtes\\cmtes14.txt\n",
      "Successfully read C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\cmtes\\cmtes22.txt\n",
      "Successfully read C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\cmtes\\cmtes20.txt\n",
      "Successfully read C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\cmtes\\cmtes18.txt\n",
      "Shape of the concatenated dataframe: (115651, 14)\n",
      "Concatenated file saved to C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\cmtes.csv\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T18:49:29.989713Z",
     "start_time": "2024-08-16T18:49:14.606896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import concurrent.futures\n",
    "\n",
    "# Path to the CSV files\n",
    "pacs2cand = r'C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\pacs\\*.txt'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "all_files = glob.glob(pacs2cand)\n",
    "\n",
    "# List of custom headers\n",
    "headers = [\"Cycle\", \"FECRecNo\", \"PACID\", \"CID\", \"Amount\", \"Date\", \"RealCode\", \"Type\", \"DI\", \"FECCandID\"]\n",
    "\n",
    "# Function to read a single CSV file with specified headers\n",
    "def read_csv(file):\n",
    "    try:\n",
    "        df = pd.read_csv(file, encoding='ISO-8859-1', delimiter=',', quotechar='|', names=headers, low_memory=False)\n",
    "        print(f\"Successfully read {file}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Use ThreadPoolExecutor to read files in parallel\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    dfs = list(executor.map(read_csv, all_files))\n",
    "\n",
    "# Filter out any None values in the list\n",
    "dfs = [df for df in dfs if df is not None]\n",
    "\n",
    "# Concatenate all the dataframes in the list into a single dataframe\n",
    "if dfs:\n",
    "    big_df = pd.concat(dfs, ignore_index=True)\n",
    "    print(f\"Shape of the concatenated dataframe: {big_df.shape}\")\n",
    "    \n",
    "    # Save the concatenated dataframe to a single CSV file\n",
    "    output_path = r'C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\pacs.csv'\n",
    "    big_df.to_csv(output_path, index=False)\n",
    "    print(f\"Concatenated file saved to {output_path}\")\n",
    "else:\n",
    "    print(\"No dataframes to concatenate.\")\n"
   ],
   "id": "c143560c2b289ba4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\pacs\\pacs12.txt\n",
      "Successfully read C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\pacs\\pacs10.txt\n",
      "Successfully read C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\pacs\\pacs14.txt\n",
      "Successfully read C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\pacs\\pacs18.txt\n",
      "Successfully read C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\pacs\\pacs16.txt\n",
      "Successfully read C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\pacs\\pacs22.txt\n",
      "Successfully read C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\pacs\\pacs20.txt\n",
      "Shape of the concatenated dataframe: (3592977, 10)\n",
      "Concatenated file saved to C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\pacs.csv\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "List of Pac contributions to canidates",
   "id": "b0579cccc483a8ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T18:49:59.153373Z",
     "start_time": "2024-08-16T18:49:29.989713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import concurrent.futures\n",
    "\n",
    "# Path to the CSV files\n",
    "pac2pac = r'C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\pac_other\\*.txt'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "all_files = glob.glob(pac2pac)\n",
    "\n",
    "# List of custom headers\n",
    "headers = [\n",
    "    \"Cycle\", \"FECRecNo\", \"Filerid\", \"DonorCmte\", \"ContribLendTrans\", \"City\", \"State\", \n",
    "    \"Zip\", \"FECOccEmp\", \"Primcode\", \"Date\", \"Amount\", \"RecipID\", \"Party\", \"Otherid\", \n",
    "    \"RecipCode\", \"RecipPrimcode\", \"Amend\", \"Report\", \"PG\", \"Microfilm\", \"Type\", \"RealCode\", \"Source\"\n",
    "]\n",
    "\n",
    "# Function to read a single CSV file with specified headers\n",
    "def read_csv(file):\n",
    "    try:\n",
    "        df = pd.read_csv(file, encoding='ISO-8859-1', delimiter=',', quotechar='|', names=headers, low_memory=False)\n",
    "        print(f\"Successfully read {file}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Use ThreadPoolExecutor to read files in parallel\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    dfs = list(executor.map(read_csv, all_files))\n",
    "\n",
    "# Filter out any None values in the list\n",
    "dfs = [df for df in dfs if df is not None]\n",
    "\n",
    "# Concatenate all the dataframes in the list into a single dataframe\n",
    "if dfs:\n",
    "    big_df = pd.concat(dfs, ignore_index=True)\n",
    "    print(f\"Shape of the concatenated dataframe: {big_df.shape}\")\n",
    "    \n",
    "    # Save the concatenated dataframe to a single CSV file\n",
    "    output_path = r'C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\pac2pac.csv'\n",
    "    big_df.to_csv(output_path, index=False)\n",
    "    print(f\"Concatenated file saved to {output_path}\")\n",
    "else:\n",
    "    print(\"No dataframes to concatenate.\")\n"
   ],
   "id": "4ab0731b9c8e3ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\pac_other\\pac_other10.txt\n",
      "Successfully read C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\pac_other\\pac_other14.txt\n",
      "Successfully read C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\pac_other\\pac_other12.txt\n",
      "Successfully read C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\pac_other\\pac_other16.txt\n",
      "Successfully read C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\pac_other\\pac_other18.txt\n",
      "Successfully read C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\pac_other\\pac_other20.txt\n",
      "Successfully read C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\pac_other\\pac_other22.txt\n",
      "Shape of the concatenated dataframe: (2631064, 24)\n",
      "Concatenated file saved to C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\pac2pac.csv\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "List of Citizens donating to poltical canidates",
   "id": "a343e1cf2267e3f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T00:14:25.452582Z",
     "start_time": "2024-08-17T00:13:56.554470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import concurrent.futures\n",
    "\n",
    "# Path to the CSV files\n",
    "indiv = r'C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\Campaign Finance\\indivs\\*.txt'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "all_files = glob.glob(indiv)\n",
    "\n",
    "# List of custom headers and their associated data types\n",
    "data_types = {\n",
    "    \"Cycle\": str,\n",
    "    \"FECTransID\": str,\n",
    "    \"ContribID\": str,\n",
    "    \"Contrib\": str,\n",
    "    \"RecipID\": str,\n",
    "    \"Orgname\": str,\n",
    "    \"UltOrg\": str,\n",
    "    \"RealCode\": str,\n",
    "    \"Date\": str,  # Consider converting this to datetime after reading\n",
    "    \"Amount\": 'int64',\n",
    "    \"Street\": str,\n",
    "    \"City\": str,\n",
    "    \"State\": str,\n",
    "    \"Zip\": str,\n",
    "    \"RecipCode\": str,\n",
    "    \"Type\": str,\n",
    "    \"CmteID\": str,\n",
    "    \"OtherID\": str,\n",
    "    \"Gender\": str,\n",
    "    \"Microfilm\": str,\n",
    "    \"Occupation\": str,\n",
    "    \"Employer\": str,\n",
    "    \"Source\": str\n",
    "}\n",
    "\n",
    "# Function to read a single CSV file with specified headers and data types\n",
    "def read_csv(file):\n",
    "    try:\n",
    "        df = pd.read_csv(file, encoding='ISO-8859-1', delimiter=',', quotechar='|', dtype=data_types, names=list(data_types.keys()), low_memory=False)\n",
    "        print(f\"Successfully read {file}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Use ThreadPoolExecutor to read files in parallel\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    dfs = list(executor.map(read_csv, all_files))\n",
    "\n",
    "# Filter out any None values in the list\n",
    "dfs = [df for df in dfs if df is not None]\n",
    "\n",
    "# Concatenate all the dataframes in the list into a single dataframe\n",
    "if dfs:\n",
    "    big_df = pd.concat(dfs, ignore_index=True)\n",
    "    print(f\"Shape of the concatenated dataframe: {big_df.shape}\")\n",
    "    \n",
    "    # Save the concatenated dataframe to a single CSV file\n",
    "    output_path = r'C:\\Users\\Kameron\\Documents\\ESG Thesis\\Data\\Political_Contributions\\indivss.csv'\n",
    "    big_df.to_csv(output_path, index=False)\n",
    "    print(f\"Concatenated file saved to {output_path}\")\n",
    "else:\n",
    "    print(\"No dataframes to concatenate.\")\n"
   ]
